:uri:
:toc: manual
:toc-placement: preamble
:numbered:
:rulesspreadsheet: link:https://docs.google.com/spreadsheets/d/1C4jbSADmHJvLL3PBBBSEB54L8G_I6NN5rblWIGymAXg/edit#gid=1640119171[GPTE Accreditation Rules Spreadsheet with validation]
:designdoc: link:https://docs.google.com/document/d/1rFioqj5uhLtdoUEfHHBEwh4_-bW7vqEc5N0R24tN9FU/edit#[GPTE Reporting design document]

= GPTE Reporting

Administration Guide


== Overview

=== Purpose and design
High level purpose and system design of the `GPTE Reporting` project can be found in the  {designdoc} (best viewed in Google Chrome).

=== Audience
The intended audience of this document architects, developers and administrators of the GPTE Reporting solution.

== Skills

=== Business User / Project Mgmt
. Experience collaborating in a team using email and slack.
. Experience using a browser to view web based reports.
. Experience using Google Spreadsheets.

=== Architect
. All of the skills required of a business user.
. Experience designing _3-tier_, transactional applications.
. Experience desiging database schemas to support transactional and reporting requirements.
. Experience documenting a software architecture.

=== Operations and QA Team Member
. All of the skills required of a business user.
. RHCSA or equivalent experience.
. Experience with Ansible.
. Experience with Git.
. Experience with administration of java projects using its defacto build tool:  Maven.
. Experience with JBoss EAP administration.
. Experience using Google Spreadsheet's javascript extension functionality:  _Google App Script_.
. Experience with use and administration of a MariaDB RDBMS.
. Experience using Asciidoc (ie: to update this document).

=== Development Team Member
. All of the skills required of an operations team member.
. Experience with Java development and its defacto build tool: Maven.
. Experience developing _transactional_ applications using the following patterns and archictures:
.. Dependency Injection
.. DAOs
.. SOA
. Experience using the following Java based client libraries:
.. HTTP (in particular, following OAUTH2 workflows)
.. LDAP
.. JDBC
. Experience developing services using JBoss Fuse.
. Experience with the Drools and Dashbuilder components of JBoss BPMS.
. Experience with database development using MariaDB.

== Pre-Reqs

=== Technical

. Github account with, at a minimum, `viewer` credentials to the `github.com/redhat-gpe` organization.
. Workstation (bare metal or VM) with 8GB RAM, 4 CPUs and 100GB disk.

== GPTE Reporting VMs

Each environment consists of a VM. Here is a list of the current VMs.

. *prod* :   apps-iad01.opentl.com / reporting.opentlc.com
. *qa*   :   qa-fso00   / qa.opentlc.com
. *dev*  :   apps-iad00 / qa.opentlc.com

The following shell commands will allow you access to the VMs:

. *prod* :   ssh <OPENTLC User ID>@apps-iad01.opentlc.com
. *qa*   :   ssh <OPENTLC User ID>@qa-fso00.opentlc.com
. *dev*  :   ssh <OPENTLC User ID>@apps-iad00.opentlc.com

=== SSH access
To gain access to the GPTE Reporting machines, the following is necessary:

. UPload your public  ssh key to https://account.opentlc.com/update
. Send a request to the following email to have your opentlc account add to the role `opentlc-appadmin-users` : opentlc-infra-admins@redhat.com

== GPTE Reporting URLs

GPTE Reporting has three environments:  prod, qa and dev.

FQDN of each environment is as follows:

. *prod* :   reporting.opentlc.com
. *qa*   :   qa.opentlc.com
. *dev*  :   dev.opentlc.com

Each of these environments runs the same GPTE Reporting services.


URLs to each GPTE Reporting service are as follows:

. *Dashbuilder* :  https://<fqdn>/dashbuilder

== GPTE Reporting Email Addresses

GPTE Reporting has an email address assigned to each environment. These email address inboxes are used to consume received data files.

. *prod* :   gpeskillsdev@gmail.com
. *qa*   :   rhtgpteqa@yahoo.com
. *dev*  :   rhtgptetest@yahoo.com

You can also login to these inboxes using the credentials found in each environments properties file. GPTE will reprocess emails that are marked unread, so marking an email unread will kick off the processing of the email's attached file.

== GPTE Reporting Shell Alias Shortcuts

Each environment contains shell aliases to tail logs, bounce services, and gain access to MySQL databases.

. *ta* :   Tails the accreditation log
. *ba* :   Bounces the accreditation services
. *tg* :   Tails the JBoss EAP log (GPTE)
. *bg* :   Bounces the JBoss EAP services
. *td* :   Tails the DashBuilder log
. *bd* :   Bounces the DashBuilder services
. *mroot* :   Opens a MySQL mariadb connection to allow you to run queries on the GPTE Reporting databases.

== RESTful APIs

https://reporting.opentlc.com/gpte-reporting-swagger/

== Provisioning
Review `base_install.yml` and `update.yml` scripts in _$PROJECT_HOME/infrastructure/ansible_ directory.

== Updating

It is possible to update all GPTE Reporting environment (prod, qa & dev) via GPTE's Jenkins environment.

A Jenkins pipeline has been created that triggers the ansible provisioning and updating functionaility of GPTE Reporting.

NOTE:  MAKE SURE TARGET ENVIRONMENT DOES NOT HAVE ANY LOCAL CHANGES IN /opt/OPEN_Reporting.
If there are existing, un-committed and un-pushed changes in the target environment, this Jenkins job will fail.

You can check this by going to /opt/OPEN_Reporting and running "git status".  If the response is the below, you are free to trigger the Jenkins build job.

"
# On branch master
nothing to commit, working directory clean
"

You can also check what the local properties are by the command "vi /opt/OPEN_Reporting/properties/qa.properties"


To update a GPTE Reporting environment, execute the following:

. Point your browser to:  `https://forge.opentlc.com/jenkins`
. Authenticate using your _OPENTLC_ userId and password.
. Navigate to `GPTE Reporting -> update_gpte_reporting`
+
image::images/click_update_gpte_reporting.png[]

. In the left panel, click: `Build with Parameters`.
. In the _gpte_env_ parameter, specify the environment that should be updated (prod, qa, dev):
+
image::images/updated_build.png[]
. Click: `Build`.
. Click the _build #_ for the Jenkins build that is now in progress.
. From the left panel, click: `Console Output`
. Monitor the output of the update process

== Production Database Disaster Recovery

=== Backup
. The following two production databases are periodically backed up:
.. `lms_transactional`
.. `lms_reporting`

. This back up happens nightly at 11:30pm EST.
. The backup occurs via a Jenkins job
+
image::images/prod_backup_job.png[]
. A zip of both databases can be found at the following: `forge.opentlc.com:/tmp/mysqlbackup_target/`

=== Recovery
If the production database at `reporting.opentlc.com` was to be lost, then it could be fully recovered as follows:

. Re-provision `reporting.opentlc.com` from ansible.
. Populate the `lms_transactional` and `lms_reporting` databases from the backups:
.. ssh reporting.opentlc.com
.. mkdir -p /tmp/mysqlbackup_target
.. scp forge.opentlc.com:/tmp/mysqlbackup_target/* /tmp/mysqlbackup_target
.. unzip both files in /tmp/mysqlbackup_target
.. Use the command line mysql utility to import into each corresponding database.

NOTE: The `dashbuilder` database will also be needed.  The `dashbuilder` database can be dumped from `dev.opentlc.com`.


== GPTE Reporting Databases

GPTE Reporting has three MySQL databases:

. `lms_transactional`
.. The OLTP (online transaction processing) database, commonly referred to as the "transactional database".
.. Contains entities such as Students, Courses, StudentCourses, and StudentAccreditations.
.. The Drools Accreditation Logic is run on lms_transactional to populate StudentAccreditations.
. `lms_reporting`
.. The OLAP (online analytical processing) database, commonly referred to as the "reporting database".
.. This database can be thought of a view of `lms_transactional` as it is refreshed regularly using data from `lms_transactional`.
.. `lms_reporting` is the back-end for Dashbuilder, the reporting tool used for online reporting.
. `dashbuilder`
.. This database contains the objects needed for the JBoss Dashbuilder web application. All data sources, queries, reports, etc. created witin Dashbuilder are stored here.
.. `dashbuilder` contains data sources to lms_reporting and uses that data to populate the online reports.

=== Manual tasks to _lms_transactional_ database

. Seed the `lms_transactional` database with test data
+
-----
mysql -u root lms_transactional <  db_scripts/lms_transactional_ddl.sql
mysql -u root lms_transactional < db_scripts/lms_transactional_data.sql
-----

. Periodically, create a new test datafile from a current snapshot of your `lms_transactional` database.
+
This database is used to support development and unit testing of GPTE Reporting project:
+
-----
# slim down size of lms_transactional database
mysql -u root lms_transactional -e "delete from Students where StudentID > 10399"

# Data dump to a file
mysqldump --no-create-db --no-create-info -u root lms_transactional > db_scripts/lms_transactional_data.sql

# Dump of lms_transactional schema
mysqldump -d -u root lms_transactional > db_scripts/lms_transactional_ddl.sql
-----

. Export Courses and Mappings as tsv for upload into Accreditation Rules Spreadsheet
+
-----
echo 'select cm.PrunedCourseId, c.CourseId, c.CourseName from Courses c left join CourseMappings cm on cm.courseId = c.courseId' | mysql -u root -p -B lms_transactional > /tmp/Courses_\&_Mappings.tsv
-----

== Refresh `Courses` & `CourseMappings` tables

. Make changes to the _Courses & Mappings_ sheet of {rulesspreadsheet}.
+
NOTE: Not every courseId is going to have a corresponding mapping.
For those courses without a mapping, the _PrunedCourseId_ field can either have a value of `NULL` or can be blank.

. File -> Download As -> Tab-separated values (*.tsv, current sheet).
. Using your Red Hat email account, create an email with the following:
.. *To*:  rhtgptetest@yahoo.com (for dev environment)
.. *Subject*: Course Refresh
.. *Attachment*: attach previously downloaded tsv.
. Tail the log of the GPTE Reporting server of the environment.
.. ssh <opentlc userId>@apps-iad00.opentlc.com
.. Execute the following: tg
. Send email.
. Expect results similar to the following in the log file:
+
-----
imaps://imap.mail.yahoo.com) Received file from: [<jbride@redhat.com>, <jbride@redhat.com>], subject course refresh
imaps://imap.mail.yahoo.com) moveAttachmentsToBodyAndSendToGPTEProcessingRoute() received the following # of attachments: 1
imaps://imap.mail.yahoo.com) determineAttachmentType() attachment type = course_mappings_spreadsheet
vm://cc_process-new-courses-and-mappings-uri) Following # of records deleted from Course and CourseMappings tables: 89 :  0
vm://cc_process-new-courses-and-mappings-uri) insertIntoCourseAndMappings() no mapping found for: CLI-DEL-ADCM-5593-AST
vm://cc_process-new-courses-and-mappings-uri) insertIntoCourseAndMappings() no mapping found for: MWS-DEL-ADEI-1626-AST
vm://cc_process-new-courses-and-mappings-uri) insertIntoCourseAndMappings() no mapping found for: MWS-DEL-ADMOB-7543-AST
vm://cc_process-new-courses-and-mappings-uri) Just refreshed Course and CourseMappings using the following # of records:  453
-----


== GPTE Reporting: Manual Build

-----
cd $PROJECT_HOME
mvn clean install -DskipTests
-----

== GPTE Reporting Routing Process

GPTE Reporting includes a service called: `gpte_shared_process`.
This service executes within JBoss Fuse on EAP and its purpose is the following:

. Consume data feeds sent to GPTE Reporting from external systems and users.
+
Examples include course completions from Totara and student registration data from Sumtotal.
+
This service consumes data files from a variety of endpoints such as email and local filesystem.
. Light validation of the data file (ie: proper sender email account and correct file suffix).
. Route the datafile for further processing to one of the other GPTE Reporting services also residing in the same JBoss Fuse on EAP JVM.


== Student Registration Process

== GPTE IPA integration

== Course Completion Process

=== Insertion of new Students
With some course completion data files (ie: such as from Sumtotal) there is typically sufficient information in the datafile to insert a new Student record if that student is unknown to GPTE Reporting.

If a country code is passed in the course completion datafile, then that country code is validated.
Validation behavior as follows:

. Valid country code:  log statement written at the debug level for the following class: com.redhat.gpe.coursecompletion.service.CourseCompletionServiceBean

. Missing country code:
.. Student record persisted using the following country code:  UN  (aka:  UNKNONW)
.. log statement similar to the following written at the warn level:
+
-----
10:30:34,294 WARN  [com.redhat.gpe.coursecompletion.service.CourseCompletionServiceBean] CC_5000 : cristinai@accelerasolutions.com : unknown country code:   .  Will set country as: UN
-----

. Invalid country code:
.. Student record persisted using the following country code:  UN  (aka:  UNKNONW)
.. log statement similar to the following written at the warn level:
+
-----
WARN  [com.redhat.gpe.coursecompletion.service.CourseCompletionServiceBean] CC_5000 : cristinah@accelerasolutions.com : unknown country code: United State .  Will set country as: UN
-----

. mapped country code:
.. Student record persisted using the mapped country code from CountryMappings table.
.. log statement similar to the following written at the warn level:
+
-----
WARN  [com.redhat.gpe.coursecompletion.service.CourseCompletionServiceBean] CC_5000 : cristinaj@accelerasolutions.com : mapped country : Tanzania *, United Republic of .  Will set country as: TZ
-----

=== Dokeos Course Completions (Retired)
Dokeos was retired in 2017.  The following could still be helpful in processing offline data files.

Dokeos tends to send course completions to GPTE Reporting in near real-time.
In particular, an email with a single course completion attachment file is sent as soon a student completes a course in rh.dokeos.com.

An example of a dokeos course completion can be found link:https://github.com/redhat-gpe/OPEN_Reporting/blob/master/course_completion_process/src/test/resources/sample-spreadsheets/dokeos/app_dev_eap_new.csv[here].

Upon consumption of the course completion email from dokeos, GPTE Reporting will:

. Validate the course completion.  In particular, ensure that the course referenced in the course completion is a known GPTE canonical course name as specified in lms_transactional.Courses.
. Persist the course completion (assuming the course completion validates).

Since course completions from dokeos are typically processed individually and in real time, there has not been a need to log a _Summary_ report with the processing of each course completion.
Instead, statements similar to the following are currently all that will be written to the GPTE Reporting log file (execute:  `tg` ):

-----
akropachev@bellintegrator.com : Adding student course to db: 'Red Hat OpenStack Platform for Sales' '100'
akropachev@bellintegrator.com : converting from sumtotal course completion to canonical StudentCourse. ActivityCode = CLI-SSE-IAS-11410-AST
Adding student course to db: 'Red Hat OpenStack Platform for Sales' '100'
-----

If an error occurs during either the validation or persistence of a course completion from rh.dokeos.com, an email will be sent out to GPTE Reporting system admins.

=== Sumtotal Batch Upload

==== Course Completion Processing Report
The following provides instructions on how to review a summary of the processing of a batch of Sumtotal course competions in GPTE Reporting:

. ssh into the appropriate environment of GPTE Reporting. (Dev is used in this example).
. Tail the JBoss EAP log file by executing:  `tg`.

. Email the batch file of Sumtotal course completions to the appropriate email address:
`rhtgptetest@yahoo.com` (for dev).
. Wait for anywhere between 5 - 45 seconds.  See <<troubleshoot_emails>> if nothing is observed.
. Observe the beginning of the log file for a _SumtotalCourseCompletions report_.
It will appear similar to the following:
+
-----
********** validateSumtotalCourseCompletions report:   **********
# of initial course completions  = 3348
# of rejected course completions = 0
# of course validation problems = 0
# of unknownCourseProblems = 8
# of course completions to persist = 3340
****************************************
-----

NOTE:  The above report does not list number of duplicate course completions that may or may not have been in the course completion attachment.
That information is not available from GPTE Reporting.

==== Course Completion Error detail files

Various text files that provide more details of problems that may have occurred during processing of Sumtotal batch course completion attachment files can be found on the dev machine at: `/tmp/gpte/courseCompletionIssues/` .

=== Totara Course Completions

==== Periodically pull latest Totara Course Completions to GPTE Reporting

GPTE Reporting provides the ability to periodically pull (on a configurable basis) the latest Totara course completions and persist to GPTE Reporting.

By default, this polling is disabled.
This feature can be enabled as follows:

. As the `jboss` operating system user, edit the value of the following property in the properties file specific to your environment (ie:  dev, test, or prod):
+
-----
cc_poll_totara_course_completions_input_uri=direct:poll_totara_course_completions
-----

.. Change the value such that it uses the link:http://camel.apache.org/quartz2.html[quartz2 camel component] similar to the following:
+
-----
cc_poll_totara_course_completions_input_uri=quartz2://cc_poll_totara?cron= 0 30 23 1/1 * ? *
-----

.. Save your changes to the properties file and exit.

. SSH into the local environment where you want your above cc_poll_totara_course_completions_input_uri change to be reflected

. Once you are logged in, use the command "sudo -i -u jboss"

. Navigate to the OPEN_Reporting directory (cd /opt/OPEN_Reporting)

. Use the "git pull" command to sync the local environment with the master branch in Githib.  You will be asked for the jboss user password and it is "jboss"

. Bounce the GPTE Reporting service:  `bg` .

==== Execute SQL directly on Totara Shadow DB

. ssh into GPTE dev, qa or prod environments.
. Switch users to `jboss` and change directories to: `/opt/OPEN_Reporting`.
. Determine the password for the Totara shadow db:
+
-----
$ cat properties/test.properties | grep totara_shadow_db_password
-----
. Execute the following and enter the password from the previous step at the prompt:
+
-----
psql -h 23.253.23.27 -U totara_redhat_reporting -p 5432 -W totara_redhat_reporting
-----
. You will now be logged into the Totara shadow db and can run SELECT MySQL statements.

NOTE:  Documentation of the Totara shadow database can be found here: https://autodocs.totaralms.com/schemaspy/totara-2.9/index.html


==== Manual processing
. Manually pull and process Totara Course Completions (from their _shadow database_) given a range of totara course completion Ids:
+
-----
$ curl -v -X PUT -H "LOW_CC_ID: 110756" -H "HIGH_CC_ID: 110757" \
          localhost:8205/gpte-reporting/rest/course_completions/totara
-----

==== Exception Handling

. For those Totara Course Completions that are not using a GPTE canonical course name, exception will be logged to log file (ie: _tg_ ) similar to the following:
+
-----
ERROR [process-single-totara-course-completion] ariahi@redhat.com : Totara course not found: 'How to Sell Red Hat OpenShift Container Platform'
-----
+
NOTE:  Single quotes around course name are intentional and added by GPTE Reporting to highlight if/when there might be blank spaces before or after an unknown course name in Totara.

==== Direct Access to the Totara DB and Via Web
For direct access use the following:

host: 23.253.23.27

port: 5432

username: totara_redhat_reporting

password: 87IW1o1zWff94CUXm+5w

database: totara_redhat_reporting

phpPgAdmin: https://learning.redhat.com/exhibit-2/index.php

== Accreditation Process

The GPTE Reporting service is a stand-alone (it does not run in JBoss EAP), Camel-based, Java process.

Its purpose is to:

. Parse and validate GPTE accreditation rules (in tab-delimited spreadsheet format) into Drools Rule Language (DRL) format.
. Determine accreditation based on student course completions.
+
In particular, the `accred-process` background job periodically determines new accreditations based on new course completions that have entered the system during that time period.


==== Start Accreditation Process

Shell aliases have been provided to easily bounce all GPTE Reporting services as defined earlier in this documentation.

These can be found in:  `/etc/bashrc`.

==== Monitor Accreditation Process log

Shell aliases have been provided to easily tail log files of all GPTE Reporting services as defined earlier in this documentation.

These can be found in:  `/etc/bashrc`.

==== Execute Rules Spreadsheet Validation and Parsing to DRL

. Makes changes to any of the three following tabs of the {rulesspreadsheet}:
.. `DCI Accreditation Rules`
.. `MWS Accreditation Rules`
.. `CI Accreditation Rules`
. For those spreadsheets that have changed, download them to your local workstation.
.. File -> Download As -> Tab-separated values (*.tsv, current sheet)
. Using your Red Hat email account, create an email with the following:
.. *To*:  rhtgptetest@yahoo.com (for dev)
.. *Subject*: <DCI | MWS | CI> Accreditation Rule Refresh
.. *Attachment*: attach previously downloaded tsv.
. Tail the log of GPTE `Accreditation Service` of the environment.
.. ssh <opentlc userId>@gptebuld.opentlc.com (for dev)
.. Execute the following:  ta
. Send the email.
. Expect results similar to the following in the log file:
+
-----
INFO  -new-accreditation-spreadsheet - Received rules spreadsheet.  name= GPTE Accreditation Rules with Validation - DCI Accreditation Rules.tsv : from= , subject=
INFO  AccreditationProcessBean       - changeSuffixOfRuleFileName() new rule file name = GPTE Accreditation Rules with Validation - DCI Accreditation Rules.drl
INFO  ate-drl-from-rules-spreadsheet - create-drl-from-rules-spreadsheet:  will create the following # of rules: 54 .
INFO  ate-drl-from-rules-spreadsheet - create-drl-from-rules-spreadsheet:  DRL path= src/main/resources/rules   : file name= GPTE Accreditation Rules with Validation - DCI Accreditation Rules.drl
INFO  ate-drl-from-rules-spreadsheet - create-drl-from-rules-spreadsheet:   Completed DRL generation to: src/main/resources/rules GPTE Accreditation Rules with Validation - DCI Accreditation Rules.drl
-----
. After all rule spreadsheets have been emailed and processed, bounce the GPTE `Accreditation Service`:
.. At the command line of the environment, execute:  ba

==== Invoke accreditation logic REST service
By default, the `accred-process` service runs as a background job that periodically determines accreditations.

The `accred-process` service also allows for the manual triggering of accreditation logic processing for one or more students.

==== Full Accreditation Refresh
This approach will delete all existing accreditations in the `StudentAccreditations` table.

It will then re-calculate all accreditations for all students based on their existing course completions.

. SSH into GPTE Reporting operating as the `jboss` operating system user.
. Change directories to \opt\OPEN_Reporting.
. Ensure that `accred-process` JVM is running.
. Execute:
+
-----
./bin/accreditation_batch_evaluation.sh -env=[prod|dev|qa]
-----

==== Focused Accreditation Refresh

. Invoke accreditation logic on an existing student whose course completions should lead to an accreditation.
+
-----
curl -v -X PUT  -H "ACCEPT: application/json" \
                -H "IDENTIFY_FIRED_RULES_ONLY: true" \
                -H "RESPOND_JSON: true" \
                http://$HOSTNAME:9090/gpte-accreditation/students/10387
-----

. Invoke accreditation logic on a non existent student.
+
-----
curl -v -X PUT  -H "ACCEPT: application/json" \
                -H "IDENTIFY_FIRED_RULES_ONLY: true" \
                -H "RESPOND_JSON: true" \
                http://$HOSTNAME:9090/gpte-accreditation/students/103899
-----

. Invoke accreditation logic on all students whose studentid > = 10000 and < = 11000.
+
-----
curl -v -X PUT  -H "ACCEPT: application/json" \
                -H "IDENTIFY_FIRED_RULES_ONLY: true" \
                -H "RESPOND_JSON: true" \
                -H "LOW_STUDENT_ID: 10000" \
                -H "HIGH_STUDENT_ID: 11000" \
                http://$HOSTNAME:9090/gpte-accreditation/students/batch
-----

== SalesForce Integration

https://docs.google.com/document/d/1vk_oKIzdrhiuTNCbjLgM7IoLohjw8Z2Z3d1FWPDUNsM/edit

=== General Approach
Restful Integration

=== Catalog Sync

=== Sample Python Code

== SkillsBase Integration

=== QA
The following are steps and considerations for conducting QA of SkillsBase Integration functionality.

. Authentication

... GPTE currently has two Skills Base instances:
+
-----
Test instance: https://app.skills-base.com/o/redhattest
Production instance: https://app.skills-base.com/o/redhat
-----

... Each Skills Base instance can have one unique key pair active at any time.
+
The key pair is used to request OAuth2 access tokens via the Skills Base API that can then be used to make API requests.

... Note that a maximum of one access token per instance can be active at any one time.
+
More information is available here: http://wiki.skills-base.net/index.php?title=API_introduction#Authentication

. Check # of Red Hat associates whose accreds need to be pushed to SkillsBase
+
-----
MariaDB [lms_transactional]> select count(sa.studentId) from Students s join StudentAccreditations sa on s.StudentId = sa.StudentID where sa.Processed = 0 and s.email like "%@redhat.com";
-----

. SkillsBase data schema

... The `SkillsBase Integration Service` of GPTE Reporting maintains state (in the lms_transactional database) regarding if a student is known to have a SkillsBase account and if a particular accreditation has been pushed to skillsbase.
+
This database state is found in the following fields:

.. *Students.SkillsbaseStatus*:   boolean; 0 if student does not have a skillsbase account.
.. *StudentAccreditations.Processed*: boolean; 0 if student accreditation has been pushed to SkillsBase.

... Prepare for end-to-end test using only student = gpse.training+1@redhat.com
+
-----
MariaDB [lms_transactional]>  update StudentAccreditations sa join Students s on sa.studentid = s.studentid set sa.Processed = 1 where s.Email like "%@redhat.com";
MariaDB [lms_transactional]>  update StudentAccreditations sa join Students s on sa.studentid = s.studentid set sa.Processed = 0 where s.Email = "gpse.training+1@redhat.com";
MariaDB [lms_transactional]>  update Students set SkillsbaseStatus = 1 where Email like "%@redhat.com";
MariaDB [lms_transactional]>  update Students set SkillsbaseStatus = 0 where Email = "gpse.training+1@redhat.com";
-----

. flip SkillsBase integration switch:
... Edit properties/{env}.properties :
+
-----
    sb_sendMailToStudentEnabled=true
    accred_process-push-qualification-to-skillsbase-batch=quartz2://accred_process-push-qualifications-to-skillsbase?cron=0 0/5 * 1/1 * ? *

Comment out portions of the properties file that are not needed.  In this case, because we have a cronjob firing to run the process,    comment out the below line.  This line is an an alternative optional property that if enabled, would infinitly wait for a client to "directly" invoke it.

"accred_process-push-qualification-to-skillsbase-batch=direct:push-qual-to-skillsbase-uri"
-----
... Bounce accreditation process and tail its log file:
+
-----
ba
ta
-----
. Send one or more course completions to GPTE Reporting that lead to an accreditation.
. Items of note for testing:
... sb_sendMailToStudentEnabled must be enabled for the sync to occur, accred_process-push-qualification-to-skillsbase-batch must be uncommented as well.
... Make sure that all StudentAccreditations have sa.Processed=1 other than the specific cases you want to test (sa.Processed=0) so that you do not send out unnecessary emails.
... Set sb_sendMailToStudentEnabled to false when you are done testing, and comment accred_process-push-qualification-to-skillsbase-batch back out.

=== SkillsBase Log Statements

The following can be expected in the log file of the GPTE Reporting _accreditation process_ (execute: `ta`):

. *Qualification does not already exist in SkillsBase*:
+
-----
INFO  AccreditationProcessBean       - jbride@redhat.com : skillsbase personId = 295
    statusCode = 200
    response content length = -1
    response reason phrase = OK
    response: {"status":"success","data":[{"name":"Bachelor of Science in Material Science Engineering, Univ. of Michigan, Ann Arbor","person_id":295,"status":"completed","start_date":"Sep-03-1990","end_date":"Apr-30-1994"}]}
INFO  push-qual-to-skills-base       - jbride@redhat.com : Red Hat Advanced Delivery Specialist - Cloud Management : Does not already exist in skillsbase.  Will now post to skillsbase
INFO  AccreditationProcessBean       - jbride@redhat.com : Sending the following qualification to Skills Base web service : Red Hat Advanced Delivery Specialist - Cloud Management
INFO  AccreditationProcessBean       - jbride@redhat.com : addQualification()
    endDate = 2019-04-13
    response: {"status":"success","message":null,"data":null} : status = success
INFO  push-qual-to-skills-base       - jbride@redhat.com : Student qualification complete:  assessment=Red Hat Advanced Delivery Specialist - Cloud Management
-----

. *Qualification already exists in SkillsBase*:
+
-----
INFO  AccreditationProcessBean       - jbride@redhat.com : skillsbase personId = 295
    statusCode = 200
    response content length = -1
    response reason phrase = OK
    response: {"status":"success","data":[{"name":"Bachelor of Science in Material Science Engineering, Univ. of Michigan, Ann Arbor","person_id":295,"status":"completed","start_date":"Sep-03-1990","end_date":"Apr-30-1994"},{"name":"Red Hat Advanced Delivery Specialist - Cloud Management","person_id":295,"status":"completed","start_date":"Apr-13-2017","end_date":"Apr-13-2019"}]}
INFO  push-qual-to-skills-base       - jbride@redhat.com : Qualification already exists in SkillsBase: Red Hat Advanced Delivery Specialist - Cloud Management.  Will not post to Skills Base
-----

=== Manual Push to SkillsBase

-----
$ curl -v -X PUT \
          localhost:9090/gpte-accreditation/skillsbase/students/59218
-----

== Emails
GPTE Reporting has services that for various business use cases both send and consume emails.

=== Sending emails

GPTE Reporting has the ability enable / disable the delivery of emails.
This feature may be useful in the `dev` and/or `qa` environment.

. Edit /opt/OPEN_Reporting/properties/<env>.properties.
. Change value of the following property:
+
-----
gpte_enable_all_emails=<true/false>
-----
.  Save the change.
.  Bounce GPTE Reporting service:  `bg`
. OPTIONAL:  view delivery of emails to remote mail router:
+
-----
$ tail -f /var/log/maillog
-----

[[troubleshoot_emails]]
=== Troubleshoot Consumption of Emails

GPTE Reporting consumes, parses and processes the data from emails to support various functionality, ie:  course completions and student registrations.

While tailing the log file of GPTE Reporting (ie:  `tg` ), if no indication of the consumption of that email appears, one of the following may be the root problem:

. *Unknown attachment type*
+
GPTE Reporting's email inboxes receive spam.
If the email attachment is of an unknown type, the email is not processed and nothing is written to the log.
Make sure you are sending a known attachment type.
If working with the GPTE Reporting dev environment, try sending a known working email attachment:  ie, resend a single test course completion.

. *Camel Mail component connection is stale*
.. The Camel _mail_ component is used to consume emails.
More often than not, consumption of those emails occurs without issue.  For example, the camel mail component has been running fine in production for months.
.. Occasionally, however, it might appear that the Camel _mail_ component may have gone stale.
+
To troubleshoot, start by logging into the email provider and: `mark your email as unsent`.
The camel mail provider should detect the presence of this email.

.. If you still don't observe any indication of the email being processed, bounce GPTE Reporting (ie:   `bg`).

== GPTE Cost Reporting
https://docs.google.com/document/d/1J9suQNSvHPLpGhoiXJDn3Qu90RrbX_Gpxq9gTw8hnE0/edit#heading=h.5jbd4bzcvhoc

ifdef::showscript[]

=== activemq-artemis install

NOTE:  artemis is not yet used.  Disregard this section

-----
# sudo yum install -y libaio-devel
# sudo su - jboss
$ cd /opt
$ git clone https://github.com/apache/activemq-artemis.git
$ cd activemq-artemis
$ mvn -Prelease install -DskipTests
$ cd artemis-distribution/target/apache-artemis-1.4.0-SNAPSHOT-bin/apache-artemis-1.4.0-SNAPSHOT
-----

endif::showscript[]
